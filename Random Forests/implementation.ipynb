{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The knowledge of Decision Trees will be assumed.\n",
    "Random Forests is an attempt to fix the variance issue of decision trees \\\n",
    "and also use more than one decision tree to make better decisions.\n",
    "Training:\n",
    "\n",
    "1. Bootstrapping: randomly split data into \\\n",
    "   n times (n_estimators which would a hyperparameter) with replacement to make \\\n",
    "   sure each one has the same size as the original data set.\n",
    "2. Decide on the max features (max_features is a hyperparameter) using an algorithm \\\n",
    "   like sqrt or log2. In this case, we'll be using sqrt\n",
    "3. Randomly take the subset of features for each tree (the number of features is \\\n",
    "   random up to max features)\n",
    "4. Run the decision tree algorithm and take the majority vote \\\n",
    "   (classification) or the average (regression) for each tree prediction\n",
    "\n",
    "Testing:\n",
    "Same thing as running Decision trees for entire dataset but take average or majority vote \\\n",
    "and find the accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "import random\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from csv import reader\n",
    "\n",
    "# dataset = list()\n",
    "# with open(\"./sonar.all-data.csv\", \"r\") as file:\n",
    "#     csv_reader = reader(file)\n",
    "#     for row in csv_reader:\n",
    "#         if not row:\n",
    "#             continue\n",
    "#         dataset.append(row)\n",
    "# dataset = np.array(dataset)\n",
    "# X, y = dataset[:, :-1], pd.Categorical(pd.Series(dataset[:, -1])).codes\n",
    "# df = pd.read_csv(\"./sonar.all-data.csv\")\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y, test_size=0.33, random_state=42\n",
    "# )\n",
    "# X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris, load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# # Load the Iris dataset\n",
    "# iris = load_iris()\n",
    "# X = iris.data\n",
    "# y = iris.target\n",
    "\n",
    "# Load the Breast Cancer Wisconsin (Diagnostic) dataset\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.029e+00, 1.733e+01, 5.879e+01, ..., 1.750e-01, 4.228e-01,\n",
       "        1.175e-01],\n",
       "       [2.109e+01, 2.657e+01, 1.427e+02, ..., 2.903e-01, 4.098e-01,\n",
       "        1.284e-01],\n",
       "       [9.173e+00, 1.386e+01, 5.920e+01, ..., 5.087e-02, 3.282e-01,\n",
       "        8.490e-02],\n",
       "       ...,\n",
       "       [1.429e+01, 1.682e+01, 9.030e+01, ..., 3.333e-02, 2.458e-01,\n",
       "        6.120e-02],\n",
       "       [1.398e+01, 1.962e+01, 9.112e+01, ..., 1.827e-01, 3.179e-01,\n",
       "        1.055e-01],\n",
       "       [1.218e+01, 2.052e+01, 7.722e+01, ..., 7.431e-02, 2.694e-01,\n",
       "        6.878e-02]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryTree:\n",
    "    def __init__(\n",
    "        self,\n",
    "        val: float | None = None,\n",
    "        pos: int | None = None,\n",
    "        majority_class: int | None = None,\n",
    "        left: BinaryTree | None = None,\n",
    "        right: BinaryTree | None = None,\n",
    "    ):\n",
    "        self.val = val\n",
    "        self.pos = pos\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.majority_class = majority_class\n",
    "\n",
    "    def display(self):\n",
    "        lines, *_ = self._display_aux()\n",
    "        for line in lines:\n",
    "            print(line)\n",
    "\n",
    "    def _display_aux(self):\n",
    "        \"\"\"Returns list of strings, width, height, and horizontal coordinate of the root.\"\"\"\n",
    "        # No child.\n",
    "        if self.right is None and self.left is None:\n",
    "            line = \"%s\" % self.pos\n",
    "            width = len(line)\n",
    "            height = 1\n",
    "            middle = width // 2\n",
    "            return [line], width, height, middle\n",
    "\n",
    "        # Only left child.\n",
    "        if self.right is None:\n",
    "            lines, n, p, x = self.left._display_aux()\n",
    "            s = \"%s\" % self.pos\n",
    "            u = len(s)\n",
    "            first_line = (x + 1) * \" \" + (n - x - 1) * \"_\" + s\n",
    "            second_line = x * \" \" + \"/\" + (n - x - 1 + u) * \" \"\n",
    "            shifted_lines = [line + u * \" \" for line in lines]\n",
    "            return [first_line, second_line] + shifted_lines, n + u, p + 2, n + u // 2\n",
    "\n",
    "        # Only right child.\n",
    "        if self.left is None:\n",
    "            lines, n, p, x = self.right._display_aux()\n",
    "            s = \"%s\" % self.pos\n",
    "            u = len(s)\n",
    "            first_line = s + x * \"_\" + (n - x) * \" \"\n",
    "            second_line = (u + x) * \" \" + \"\\\\\" + (n - x - 1) * \" \"\n",
    "            shifted_lines = [u * \" \" + line for line in lines]\n",
    "            return [first_line, second_line] + shifted_lines, n + u, p + 2, u // 2\n",
    "\n",
    "        # Two children.\n",
    "        left, n, p, x = self.left._display_aux()\n",
    "        right, m, q, y = self.right._display_aux()\n",
    "        s = \"%s\" % self.pos\n",
    "        u = len(s)\n",
    "        first_line = (x + 1) * \" \" + (n - x - 1) * \"_\" + s + y * \"_\" + (m - y) * \" \"\n",
    "        second_line = (\n",
    "            x * \" \" + \"/\" + (n - x - 1 + u + y) * \" \" + \"\\\\\" + (m - y - 1) * \" \"\n",
    "        )\n",
    "        if p < q:\n",
    "            left += [n * \" \"] * (q - p)\n",
    "        elif q < p:\n",
    "            right += [m * \" \"] * (p - q)\n",
    "        zipped_lines = zip(left, right)\n",
    "        lines = [first_line, second_line] + [a + u * \" \" + b for a, b in zipped_lines]\n",
    "        return lines, n + m + u, max(p, q) + 2, n + u // 2\n",
    "\n",
    "    def print(self):\n",
    "        if not self:\n",
    "            return\n",
    "        print(self.val, self.majority_class)\n",
    "        if self.left:\n",
    "            self.left.print()\n",
    "        if self.right:\n",
    "            self.right.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3342573055.py, line 32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[16], line 32\u001b[1;36m\u001b[0m\n\u001b[1;33m    for i in np.random.choice(range(len(row) - 2), size=random.randint(1, int(sqrt((len(row) - 1))), replace=False):\u001b[0m\n\u001b[1;37m                                                                                                                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(self, max_tree_depth=5):\n",
    "        self.max_tree_depth = max_tree_depth\n",
    "\n",
    "    def _entropy(self, probabilities):\n",
    "        epsilon = 1e-10\n",
    "        return -np.sum((probabilities + epsilon) * np.log2(probabilities + epsilon))\n",
    "\n",
    "    def _information_gain(self, parent_probabilities, children_probabilities, weights):\n",
    "        return self._entropy(parent_probabilities) - np.sum(\n",
    "            [\n",
    "                weight * self._entropy(child_probabilities)\n",
    "                for weight, child_probabilities in zip(weights, children_probabilities)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def _gain_split(self, value, index, dataset):\n",
    "        left_dataset = dataset[dataset[:, index] <= value]\n",
    "        right_dataset = dataset[dataset[:, index] > value]\n",
    "        return left_dataset, right_dataset\n",
    "\n",
    "    def _get_best_split(\n",
    "        self,\n",
    "        parent_dataset: np.ndarray,\n",
    "        parent_dataset_size: int,\n",
    "        parent_probabilities: np.ndarray,\n",
    "        class_size: int,\n",
    "        counter=0,\n",
    "    ):\n",
    "        max_ig = float(\"-inf\")\n",
    "        for row in parent_dataset:\n",
    "            for i in np.random.choice(\n",
    "                range(len(row) - 2),\n",
    "                size=random.randint(1, int(sqrt((len(row) - 1)))),\n",
    "                replace=False,\n",
    "            ):\n",
    "                left_dataset, right_dataset = self._gain_split(\n",
    "                    row[i], i, parent_dataset\n",
    "                )\n",
    "                left_size = len(left_dataset)\n",
    "                right_size = len(right_dataset)\n",
    "                total_groups_count = left_size + right_size\n",
    "\n",
    "                probabilities_left = (\n",
    "                    np.bincount(left_dataset[:, -1].astype(int), minlength=class_size)\n",
    "                    / total_groups_count\n",
    "                )\n",
    "                probabilities_right = (\n",
    "                    np.bincount(right_dataset[:, -1].astype(int), minlength=class_size)\n",
    "                    / total_groups_count\n",
    "                )\n",
    "\n",
    "                ig = self._information_gain(\n",
    "                    parent_probabilities,\n",
    "                    np.array([probabilities_left, probabilities_right]),\n",
    "                    np.array(\n",
    "                        [\n",
    "                            left_size / parent_dataset_size,\n",
    "                            right_size / parent_dataset_size,\n",
    "                        ]\n",
    "                    ),\n",
    "                )\n",
    "                if max_ig < ig:\n",
    "                    max_ig = ig\n",
    "                    optimal_value = row[i]\n",
    "                    index = i\n",
    "                    optimal_left_dataset = left_dataset\n",
    "                    optimal_right_dataset = right_dataset\n",
    "                    optimal_left_size = left_size\n",
    "                    optimal_right_size = right_size\n",
    "                    optimal_probabilities_left = probabilities_left\n",
    "                    optimal_probabilities_right = probabilities_right\n",
    "        if parent_dataset is not None and not parent_dataset.size:\n",
    "            return None\n",
    "        root = BinaryTree(optimal_value, index)\n",
    "        if counter < self.max_tree_depth:\n",
    "            root.left = self._get_best_split(\n",
    "                optimal_left_dataset,\n",
    "                optimal_left_size,\n",
    "                optimal_probabilities_left,\n",
    "                class_size,\n",
    "                counter + 1,\n",
    "            )\n",
    "            root.right = self._get_best_split(\n",
    "                optimal_right_dataset,\n",
    "                optimal_right_size,\n",
    "                optimal_probabilities_right,\n",
    "                class_size,\n",
    "                counter + 1,\n",
    "            )\n",
    "        # add majority_class to leaf node\n",
    "        if not root.left and not root.right:\n",
    "            root.majority_class = np.argmax(\n",
    "                np.bincount(parent_dataset[:, -1].astype(int))\n",
    "            )\n",
    "        return root\n",
    "\n",
    "    def fit(self, X: np.ndarray, class_values: np.ndarray):\n",
    "        class_size = len(np.unique(class_values))\n",
    "        self.class_values = class_values\n",
    "        dataset = np.concatenate((X, class_values.reshape((-1, 1))), axis=1)\n",
    "        dataset_size = len(dataset)\n",
    "        self.row_size = len(dataset[0])\n",
    "        decision_tree = self._get_best_split(\n",
    "            dataset, dataset_size, np.bincount(class_values) / dataset_size, class_size\n",
    "        )\n",
    "        # decision_tree.display()\n",
    "        # decision_tree.print()\n",
    "        self.decision_tree = decision_tree\n",
    "\n",
    "    def _traverse_tree(self, X: np.ndarray, root: BinaryTree):\n",
    "        if not root:\n",
    "            return\n",
    "        if not root.left and not root.right:\n",
    "            X_set = set([tuple(x) for x in X])\n",
    "            for i, x in enumerate(self.X):\n",
    "                if tuple(x) in X_set:\n",
    "                    self.results[i] = root.majority_class\n",
    "            return\n",
    "        left_dataset, right_dataset = self._gain_split(root.val, root.pos, X)\n",
    "        self._traverse_tree(left_dataset, root.left)\n",
    "        self._traverse_tree(right_dataset, root.right)\n",
    "\n",
    "    def predict(self, X: np.ndarray):\n",
    "        self.results = [0] * len(X)\n",
    "        self.X = X\n",
    "        self._traverse_tree(X, self.decision_tree)\n",
    "        return np.array(self.results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    def __init__(self, max_tree_depth=5, n_estimators=100, max_features=\"sqrt\"):\n",
    "        self.max_tree_depth = max_tree_depth\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_features = max_features\n",
    "        self.forest: List[DecisionTree] = []\n",
    "\n",
    "    def _bootstrap(self, dataset: np.ndarray):\n",
    "        size = len(dataset)\n",
    "        random_indices = np.random.choice(range(size), size=size, replace=True)\n",
    "        return dataset[random_indices]\n",
    "\n",
    "    def _get_random_features_positions(self, row_size: int, num_features: int):\n",
    "        return list(np.random.choice(row_size, size=num_features, replace=False))\n",
    "\n",
    "    def fit(self, X: np.ndarray, class_values: np.ndarray):\n",
    "        row_size = len(X[0])\n",
    "        if self.max_features == \"sqrt\":\n",
    "            self.max_features = int(sqrt(row_size))\n",
    "        dataset = np.concatenate((X, class_values.reshape((-1, 1))), axis=1)\n",
    "        for _ in range(self.n_estimators):\n",
    "            filtered_dataset = self._bootstrap(dataset)\n",
    "            new_X = filtered_dataset[:, :-1]\n",
    "            new_class_values = filtered_dataset[:, -1].astype(int)\n",
    "            tree = DecisionTree(self.max_tree_depth)\n",
    "            tree.fit(new_X, new_class_values)\n",
    "            self.forest.append(tree)\n",
    "\n",
    "    def predict(self, X: np.ndarray):\n",
    "        predictions = []\n",
    "        for tree in self.forest:\n",
    "            prediction = tree.predict(X)\n",
    "            predictions.append(prediction)\n",
    "        predictions = np.array(predictions)\n",
    "        results = []\n",
    "        # save(predictions)\n",
    "        for i in range(len(predictions[0])):\n",
    "            results.append(np.argmax(np.bincount(predictions[:, i])))\n",
    "\n",
    "        return np.array(results)\n",
    "\n",
    "\n",
    "def save(predictions_list: List[List]):\n",
    "    file_path = \"predictions.txt\"\n",
    "    with open(file_path, \"w\") as file:\n",
    "        for sublist in predictions_list:\n",
    "            line = \" \".join(str(element) for element in sublist)\n",
    "            file.write(line + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 1 0 0 0 0 1 1 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
      " 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 0 0 1 1 0 0 1 0\n",
      " 1 1 1 1 1 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 1 0 0 1 0 0 1 1 1 0 0 1 0\n",
      " 1 1 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9473684210526315"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DecisionTree(max_tree_depth=5)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "\n",
    "model = RandomForest(max_tree_depth=5, n_estimators=100)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(y_pred)\n",
    "print(y_test.shape, y_pred.shape)\n",
    "# print(\"Percision:\", accuracy)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 1 0 0 0 0 1 1 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0\n",
      " 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 0 0 1 1 0 0 1 0\n",
      " 1 1 1 1 1 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 1 0 0 1 0 0 1 1 1 0 1 1 0\n",
      " 1 1 0]\n",
      "(114, 30)\n",
      "Accuracy: 0.9649122807017544\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create a Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    criterion=\"entropy\",\n",
    "    max_depth=5,\n",
    "    max_features=\"sqrt\",\n",
    "    bootstrap=True,\n",
    ")\n",
    "\n",
    "# Train the Random Forest classifier\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "print(y_pred)\n",
    "print(X_test.shape)\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
