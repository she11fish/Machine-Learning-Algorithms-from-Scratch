{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree is a supervised machine learning algorithm that solves classification and regression problems. \\\n",
    "A good way to think about decision tree is node is a greedy way (only focus on best current threshold) to \\\n",
    "find a condition that splits based on the values in the dataset as reference (continuous values have infinite possibilites). \\\n",
    "After that, we figure out the best split that can be made based on the data we have. In this case, we will start a 50 50 split.\n",
    "The one we're going to do is one that relies on entropy, meaning that we're binary splits when making decisions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm is done in the following for training (we're assuming binary for this one):\n",
    "\n",
    "1. Have output labeled data set to determine the probability\n",
    "2. Split Greedily (there are other heuristics for splitting) by taking all features and determining the maximum Information Gain\n",
    "3. Do it recursively until a stopping criterion is reached (can be max depth, min sample leaf, min impurity decrease, or min sample split)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To continue with this algorithm, we have to know how to calculate the Information Gain to get the best choice.\n",
    "$$IG = E(parent) - \\sum w_{i}E(child_i)$$\n",
    "Where E is entropy. We can use other functions like Gini impurity. $w_{i}$ here means the weight per child which is $w_{i} = \\frac{\\text{child i sample size}}{\\text{parent sample size}}$\n",
    "$$E = -\\sum p_i\\log_{2}(p_i)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm is done in the following for testing:\n",
    "\n",
    "1. Iterate through the tree generated from training.\n",
    "2. Compare the result with actual answer by using accuracy or any other evaluation metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris, load_breast_cancer, load_wine, load_digits\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X_iris, y_iris = iris.data, iris.target\n",
    "\n",
    "# Load the Breast Cancer dataset\n",
    "cancer = load_breast_cancer()\n",
    "X_cancer, y_cancer = cancer.data, cancer.target\n",
    "\n",
    "# Load the Wine dataset\n",
    "wine = load_wine()\n",
    "X_wine, y_wine = wine.data, wine.target\n",
    "\n",
    "# Load the Digits dataset\n",
    "digits = load_digits()\n",
    "X_digits, y_digits = digits.data, digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((120, 4), (30, 4), (120,), (30,))"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the Iris dataset into training and testing sets\n",
    "# X_iris_train, X_iris_test, y_iris_train, y_iris_test = train_test_split(X_iris, y_iris, test_size=0.2, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_iris, y_iris, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# # Split the Breast Cancer dataset into training and testing sets\n",
    "# X_cancer_train, X_cancer_test, y_cancer_train, y_cancer_test = train_test_split(X_cancer, y_cancer, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Split the Wine dataset into training and testing sets\n",
    "# X_wine_train, X_wine_test, y_wine_train, y_wine_test = train_test_split(X_wine, y_wine, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Split the Digits dataset into training and testing sets\n",
    "# X_digits_train, X_digits_test, y_digits_train, y_digits_test = train_test_split(X_digits, y_digits, test_size=0.2, random_state=42)\n",
    "# X_iris_train, X_iris_test, y_iris_train, y_iris_test, X_cancer_train, X_cancer_test, y_cancer_train, y_cancer_test, X_digits_train, X_digits_test, y_digits_train, y_digits_test\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((237, 13), (60, 13), (237,), (60,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data\"\n",
    "names = [\n",
    "    \"age\",\n",
    "    \"sex\",\n",
    "    \"cp\",\n",
    "    \"trestbps\",\n",
    "    \"chol\",\n",
    "    \"fbs\",\n",
    "    \"restecg\",\n",
    "    \"thalach\",\n",
    "    \"exang\",\n",
    "    \"oldpeak\",\n",
    "    \"slope\",\n",
    "    \"ca\",\n",
    "    \"thal\",\n",
    "    \"target\",\n",
    "]\n",
    "df = pd.read_csv(url, names=names)\n",
    "\n",
    "# Replace missing values (represented as '?') with NaN\n",
    "df.replace(\"?\", pd.NA, inplace=True)\n",
    "\n",
    "# Drop rows with missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Convert categorical features to numerical\n",
    "df[\"sex\"] = df[\"sex\"].astype(int)\n",
    "df[\"cp\"] = df[\"cp\"].astype(int)\n",
    "df[\"fbs\"] = df[\"fbs\"].astype(int)\n",
    "df[\"restecg\"] = df[\"restecg\"].astype(int)\n",
    "df[\"exang\"] = df[\"exang\"].astype(int)\n",
    "df[\"slope\"] = df[\"slope\"].astype(int)\n",
    "df[\"ca\"] = df[\"ca\"].astype(float)\n",
    "df[\"thal\"] = df[\"thal\"].astype(float)\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop(\"target\", axis=1).to_numpy()\n",
    "y = df[\"target\"].to_numpy()\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 223\u001b[0m\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults)\n\u001b[0;32m    222\u001b[0m model \u001b[38;5;241m=\u001b[39m DecisionTree(max_tree_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m--> 223\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(\u001b[43mX_train\u001b[49m, y_train)\n\u001b[0;32m    224\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m    225\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, y_pred)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class BinaryTree:\n",
    "    def __init__(\n",
    "        self,\n",
    "        val: float | None = None,\n",
    "        pos: int | None = None,\n",
    "        majority_class: int | None = None,\n",
    "        left: BinaryTree | None = None,\n",
    "        right: BinaryTree | None = None,\n",
    "    ):\n",
    "        self.val = val\n",
    "        self.pos = pos\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.majority_class = majority_class\n",
    "\n",
    "    def display(self):\n",
    "        lines, *_ = self._display_aux()\n",
    "        for line in lines:\n",
    "            print(line)\n",
    "\n",
    "    def _display_aux(self):\n",
    "        \"\"\"Returns list of strings, width, height, and horizontal coordinate of the root.\"\"\"\n",
    "        # No child.\n",
    "        if self.right is None and self.left is None:\n",
    "            line = \"%s\" % self.val\n",
    "            width = len(line)\n",
    "            height = 1\n",
    "            middle = width // 2\n",
    "            return [line], width, height, middle\n",
    "\n",
    "        # Only left child.\n",
    "        if self.right is None:\n",
    "            lines, n, p, x = self.left._display_aux()\n",
    "            s = \"%s\" % self.val\n",
    "            u = len(s)\n",
    "            first_line = (x + 1) * \" \" + (n - x - 1) * \"_\" + s\n",
    "            second_line = x * \" \" + \"/\" + (n - x - 1 + u) * \" \"\n",
    "            shifted_lines = [line + u * \" \" for line in lines]\n",
    "            return [first_line, second_line] + shifted_lines, n + u, p + 2, n + u // 2\n",
    "\n",
    "        # Only right child.\n",
    "        if self.left is None:\n",
    "            lines, n, p, x = self.right._display_aux()\n",
    "            s = \"%s\" % self.val\n",
    "            u = len(s)\n",
    "            first_line = s + x * \"_\" + (n - x) * \" \"\n",
    "            second_line = (u + x) * \" \" + \"\\\\\" + (n - x - 1) * \" \"\n",
    "            shifted_lines = [u * \" \" + line for line in lines]\n",
    "            return [first_line, second_line] + shifted_lines, n + u, p + 2, u // 2\n",
    "\n",
    "        # Two children.\n",
    "        left, n, p, x = self.left._display_aux()\n",
    "        right, m, q, y = self.right._display_aux()\n",
    "        s = \"%s\" % self.val\n",
    "        u = len(s)\n",
    "        first_line = (x + 1) * \" \" + (n - x - 1) * \"_\" + s + y * \"_\" + (m - y) * \" \"\n",
    "        second_line = (\n",
    "            x * \" \" + \"/\" + (n - x - 1 + u + y) * \" \" + \"\\\\\" + (m - y - 1) * \" \"\n",
    "        )\n",
    "        if p < q:\n",
    "            left += [n * \" \"] * (q - p)\n",
    "        elif q < p:\n",
    "            right += [m * \" \"] * (p - q)\n",
    "        zipped_lines = zip(left, right)\n",
    "        lines = [first_line, second_line] + [a + u * \" \" + b for a, b in zipped_lines]\n",
    "        return lines, n + m + u, max(p, q) + 2, n + u // 2\n",
    "\n",
    "    def print(self):\n",
    "        if not self:\n",
    "            return\n",
    "        print(self.val, self.majority_class)\n",
    "        if self.left:\n",
    "            self.left.print()\n",
    "        if self.right:\n",
    "            self.right.print()\n",
    "\n",
    "\n",
    "class DecisionTree:\n",
    "\n",
    "    def __init__(self, max_tree_depth=5):\n",
    "        self.max_tree_depth = max_tree_depth\n",
    "\n",
    "    def _entropy(self, probabilities):\n",
    "        epsilon = 1e-10\n",
    "        return -np.sum((probabilities + epsilon) * np.log2(probabilities + epsilon))\n",
    "\n",
    "    def _information_gain(self, parent_probabilities, children_probabilities, weights):\n",
    "        return self._entropy(parent_probabilities) - np.sum(\n",
    "            [\n",
    "                weight * self._entropy(child_probabilities)\n",
    "                for weight, child_probabilities in zip(weights, children_probabilities)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def _gain_split(self, value, index, dataset):\n",
    "        left, right = list(), list()\n",
    "        for row in dataset:\n",
    "            if row[index] > value:\n",
    "                right.append(row)\n",
    "            else:\n",
    "                left.append(row)\n",
    "        return (np.array(left), np.array(right))\n",
    "\n",
    "    def _get_best_split(\n",
    "        self,\n",
    "        parent_dataset: np.ndarray,\n",
    "        parent_dataset_size: int,\n",
    "        parent_probabilities: np.ndarray,\n",
    "        class_size: int,\n",
    "        counter=0,\n",
    "    ):\n",
    "        max_ig = float(\"-inf\")\n",
    "        for row in parent_dataset:\n",
    "            for i in range(len(row) - 1):\n",
    "                left_dataset, right_dataset = self._gain_split(\n",
    "                    row[i], i, parent_dataset\n",
    "                )\n",
    "                left_size = len(left_dataset)\n",
    "                right_size = len(right_dataset)\n",
    "                total_groups_count = left_size + right_size\n",
    "                if not len(left_dataset):\n",
    "                    left_dataset = np.array([[] * self.row_size])\n",
    "                    probabilities_left = np.array([0] * class_size)\n",
    "                else:\n",
    "                    probabilities_left = (\n",
    "                        np.bincount(\n",
    "                            left_dataset[:, -1].astype(int), minlength=class_size\n",
    "                        )\n",
    "                        / total_groups_count\n",
    "                    )\n",
    "                if not len(right_dataset):\n",
    "                    right_dataset = np.array([[] * self.row_size])\n",
    "                    probabilities_right = np.array([0] * class_size)\n",
    "                else:\n",
    "                    probabilities_right = (\n",
    "                        np.bincount(\n",
    "                            right_dataset[:, -1].astype(int), minlength=class_size\n",
    "                        )\n",
    "                        / total_groups_count\n",
    "                    )\n",
    "\n",
    "                ig = self._information_gain(\n",
    "                    parent_probabilities,\n",
    "                    np.array([probabilities_left, probabilities_right]),\n",
    "                    np.array(\n",
    "                        [\n",
    "                            left_size / parent_dataset_size,\n",
    "                            right_size / parent_dataset_size,\n",
    "                        ]\n",
    "                    ),\n",
    "                )\n",
    "                if max_ig < ig:\n",
    "                    max_ig = ig\n",
    "                    optimal_value = row[i]\n",
    "                    index = i\n",
    "                    optimal_left_dataset = left_dataset\n",
    "                    optimal_right_dataset = right_dataset\n",
    "                    optimal_left_size = left_size\n",
    "                    optimal_right_size = right_size\n",
    "                    optimal_probabilities_left = probabilities_left\n",
    "                    optimal_probabilities_right = probabilities_right\n",
    "        if parent_dataset is not None and not parent_dataset.size:\n",
    "            return None\n",
    "        root = BinaryTree(optimal_value, index)\n",
    "        if counter < self.max_tree_depth:\n",
    "            root.left = self._get_best_split(\n",
    "                optimal_left_dataset,\n",
    "                optimal_left_size,\n",
    "                optimal_probabilities_left,\n",
    "                class_size,\n",
    "                counter + 1,\n",
    "            )\n",
    "            root.right = self._get_best_split(\n",
    "                optimal_right_dataset,\n",
    "                optimal_right_size,\n",
    "                optimal_probabilities_right,\n",
    "                class_size,\n",
    "                counter + 1,\n",
    "            )\n",
    "        # add majority_class to leaf node\n",
    "        if not root.left and not root.right:\n",
    "            root.majority_class = np.argmax(\n",
    "                np.bincount(parent_dataset[:, -1].astype(int))\n",
    "            )\n",
    "        return root\n",
    "\n",
    "    def fit(self, X: np.ndarray, class_values: np.ndarray):\n",
    "        class_size = len(np.unique(class_values))\n",
    "        self.class_values = class_values\n",
    "        dataset = np.concatenate((X, class_values.reshape((-1, 1))), axis=1)\n",
    "        dataset_size = len(dataset)\n",
    "        self.row_size = len(dataset[0])\n",
    "        decision_tree = self._get_best_split(\n",
    "            dataset, dataset_size, np.bincount(class_values) / dataset_size, class_size\n",
    "        )\n",
    "        decision_tree.display()\n",
    "        self.decision_tree = decision_tree\n",
    "\n",
    "    def _traverse_tree(self, X: np.ndarray, root: BinaryTree):\n",
    "        if not root:\n",
    "            return\n",
    "        if not root.left and not root.right:\n",
    "            X_set = set([tuple(x) for x in X])\n",
    "            for i, x in enumerate(self.X):\n",
    "                if tuple(x) in X_set:\n",
    "                    self.results[i] = root.majority_class\n",
    "            return\n",
    "        left_dataset, right_dataset = self._gain_split(root.val, root.pos, X)\n",
    "        self._traverse_tree(left_dataset, root.left)\n",
    "        self._traverse_tree(right_dataset, root.right)\n",
    "\n",
    "    def predict(self, X: np.ndarray):\n",
    "        self.results = [0] * len(X)\n",
    "        self.X = X\n",
    "        self._traverse_tree(X, self.decision_tree)\n",
    "        return np.array(self.results)\n",
    "\n",
    "\n",
    "model = DecisionTree(max_tree_depth=4)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "[1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0]\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Create a decision tree classifier\n",
    "tree_clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=4, splitter=\"random\")\n",
    "\n",
    "# Train the classifier on the training data\n",
    "tree_clf.fit(X_train, y_train)\n",
    "print(tree_clf.get_n_leaves())\n",
    "# Make predictions on the testing data\n",
    "y_pred = tree_clf.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
